#!/usr/bin/env python
# coding: utf-8

# In[1]:


######### í•¨ìˆ˜ ì •ì˜ #########
# --- í•¨ìˆ˜1: ëŒ€ê¸° í•¨ìˆ˜ --- 
def time_wait(num, code): # css ì°¾ì„ë•Œ ê¹Œì§€ ëŒ€ê¸°
    try:
        wait = WebDriverWait(driver, num).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, code)))
    except:
        print(code, 'íƒœê·¸ë¥¼ ì°¾ì§€ ëª»í•˜ì˜€ìŠµë‹ˆë‹¤.')
        driver.quit()
    return wait


# In[2]:


# --- í•¨ìˆ˜2: ë§›ì§‘ ì •ë³´ ì¶œë ¥ ---
def sinchon_list_per_page():
    time.sleep(7)
    
    link1 = []

    ###### I. ê¸°ë³¸ ì •ë³´ ######
    names = driver.find_elements(By.CSS_SELECTOR, '.head_item > .tit_name > .link_name')
    types = driver.find_elements(By.CSS_SELECTOR, '.head_item > .subcategory')
    address_list = driver.find_elements(By.CSS_SELECTOR, '.info_item > .addr')
    avg_ratings = driver.find_elements(By.CSS_SELECTOR, '.rating > .score > em')

    # (3) ë§›ì§‘ ëª©ë¡
#     time.sleep(2)
    sinchon_list = driver.find_elements(By.CSS_SELECTOR, '.placelist > .PlaceItem')
    for index, sinchon in enumerate(sinchon_list):
        print(f"ë§›ì§‘ {index + 1}.")

        # (4-1) ë§›ì§‘ëª… (ID)
        sinchon_name = names[index].text
        print(sinchon_name)

        # (4-2) ìœ í˜•
        sinchon_type = types[index].text
        print(sinchon_type)

        # (4-3) ì£¼ì†Œ
        address = address_list.__getitem__(index).find_elements(By.CSS_SELECTOR, 'p')
        sinchon_addr1 = address.__getitem__(0).text
        print(sinchon_addr1)

        sinchon_addr2 = address.__getitem__(1).text[5:]
        print(sinchon_addr2)

        # (4-4) í‰ê·  ë³„ì 
        sinchon_avg_rating = avg_ratings[index].text
        print(sinchon_avg_rating)

        # (*) ë¦¬ë·° ë§í¬
        time.sleep(2)
        datas = driver.find_elements(By.XPATH, f'//*[@id="info.search.place.list"]/li[{str(index+1)}]/div[4]/a')
        for d in datas:
            link = d.get_attribute('href')
            link1.append(link)
        sinchon_review_link = link1[index]
        print(sinchon_review_link)

        
        
        ###### II. ë§í¬ ì •ë³´ ######
        # *** í•¨ìˆ˜3 í˜¸ì¶œ ***
        review_num, keywords, review_dates, reviewer_names, review_ratings, review_keywords, review_contents, reviewer_review_nums, reviewer_review_avg_ratings = click_until_fold(sinchon_review_link)
        print(review_num)
        print(keywords)
        print(len(review_dates))
        print(len(reviewer_names))
        print(len(review_ratings))
        print(len(review_keywords))
        print(review_contents)
        print(len(reviewer_review_nums))
        print(len(reviewer_review_avg_ratings))
        
        ###### (ë°ì´í„° >> dict ì €ì¥) ######
        dict_temp = {}
        dict_temp['ì‹ë‹¹ëª…(ID)'] = sinchon_name
        dict_temp['ìœ í˜•'] = sinchon_type
        dict_temp['ì£¼ì†Œ1'] = sinchon_addr1
        dict_temp['ì£¼ì†Œ2'] = sinchon_addr2
        dict_temp['í‰ê·  ë³„ì '] = sinchon_avg_rating
        dict_temp['ë¦¬ë·° ê°œìˆ˜'] = review_num
        dict_temp['í‚¤ì›Œë“œ'] = keywords
        dict_temp['ë¦¬ë·°ë³„ ë‚ ì§œ'] = review_dates
        dict_temp['ë¦¬ë·°ë³„ ì´ë¦„'] = reviewer_names
        dict_temp['ë¦¬ë·°ë³„ ë³„ì '] = review_ratings
        dict_temp['ë¦¬ë·°ë³„ í‚¤ì›Œë“œ'] = review_keywords
        dict_temp['ë¦¬ë·°ë³„ ë‚´ìš©'] = review_contents
        dict_temp['ë¦¬ë·°ì–´ í›„ê¸° ê°œìˆ˜'] = reviewer_review_nums
        dict_temp['ë¦¬ë·°ì–´ í‰ê·  ë³„ì '] = reviewer_review_avg_ratings
        
#         dict_temp = {
#         'ì‹ë‹¹ëª…(ID)': sinchon_name,
#         'ìœ í˜•': sinchon_type,
#         'ì£¼ì†Œ1': sinchon_addr1,
#         'ì£¼ì†Œ2': sinchon_addr2,
#         'í‰ê·  ë³„ì ': sinchon_avg_rating,
#         'ë¦¬ë·° ê°œìˆ˜': review_num,
#         'í‚¤ì›Œë“œ': keywords,
#         'ë¦¬ë·°ë³„ ë‚ ì§œ': review_dates,
#         'ë¦¬ë·°ì–´ ì´ë¦„': reviewer_names,
#         'ë¦¬ë·°ë³„ ë³„ì ': review_ratings,
#         'ë¦¬ë·°ë³„ í‚¤ì›Œë“œ': review_keywords,
#         'ë¦¬ë·°ë³„ ë‚´ìš©': review_contents,
#         'ë¦¬ë·°ì–´ í›„ê¸° ê°œìˆ˜': reviewer_review_nums,
#         'ë¦¬ë·°ì–´ í‰ê·  ë³„ì ': reviewer_review_avg_ratings
#         }

        final_list.append(dict_temp)
        print(f'<{sinchon_name}> í¬ë¡¤ë§ ì™„ë£Œ...')
        
    return final_list


# In[3]:


# --- í•¨ìˆ˜3: ë²„íŠ¼ í´ë¦­ + ë¦¬ë·° ì •ë³´ í¬ë¡¤ë§ ---
def click_until_fold(link):
    # --- í¬ë¡¬ì°½ ì˜µì…˜ --- 
    chrome_options = webdriver.ChromeOptions() 
    chrome_options.add_argument('headless') # í¬ë¡¬ì°½ ìˆ¨ê¸°ê¸°
    chrome_options.add_argument('lang=ko_KR')

    # --- í¬ë¡¬ ë“œë¼ì´ë²„ ---
    service = Service()
    release = "https://chromedriver.storage.googleapis.com/LATEST_RELEASE"
    version = requests.get(release).text
    # driver = webdriver.Chrome(service=Service(ChromeDriverManager(version=version).install()))
    driver = webdriver.Chrome(service=Service(ChromeDriverManager(version=version).install()), options=chrome_options)

    driver.get(link)
    driver.implicitly_wait(time_to_wait=5)
    index = 0
    
    while True:
#         scroll_to_y_offset('.cont_evaluation')
        try:
            # Find the "More Reviews" button element
            time.sleep(2)
            WebDriverWait(driver, 10).until(
                    EC.element_to_be_clickable((By.CSS_SELECTOR, '.link_more'))
                )

            elements = driver.find_elements(By.CSS_SELECTOR, '.link_more')
            print('**Elements Success**!')
            element = ''

            for e in elements:
                if e.text == 'í›„ê¸° ë”ë³´ê¸°':
    #                 print(f"ë‹¨ìˆ˜: {e}")
                    element = e
    #                 print(f"ë‹¨ìˆ˜: {element}")
                    print('CSS Select Success!')
                    print(f'ë²„íŠ¼ëª…: {element.text}')
                    element.send_keys(Keys.ENTER)
                    print('Click!')
                    index += 1
                    break
                if e.text == 'í›„ê¸° ì ‘ê¸°':
                    element = e.text
                    print('Click Done!')
                    break

            if element == 'í›„ê¸° ì ‘ê¸°':
                break
            
            if index == 0:
                print('No Reiews!')
                break
            
        except Exception as e:
            print(e)
            print('Error!')
            break
        
#     while True:
# #         scroll_to_y_offset('.cont_evaluation')
#         try:
#             # Find the "More Reviews" button element
#             time.sleep(2)
#             show_more_button = WebDriverWait(driver, 10).until(
#                 EC.element_to_be_clickable((By.CSS_SELECTOR, '.link_more'))
#             )
#             print('Found the CSS!')
            
#             # Get the current text of the button
#             button_text = show_more_button.text
#             print(f'ë²„íŠ¼ëª…: {button_text}')
            
#             # If the text is 'unfold', break out of the loop
#             if button_text != 'í›„ê¸° ë”ë³´ê¸°':
#                 print('Click Done!')
#                 break
                
#             # Click the button
#             show_more_button.send_keys(Keys.ENTER)
#             print("Click!")

#         except Exception as e:
#             print(e)
#             print('Error!')
#             break
    
    # Make lists
    review_dates = []
    reviewer_names = []
    review_ratings = []
    review_keywords = []
    review_contents = []
    reviewer_review_nums = []
    reviewer_review_avg_ratings = []
    print("Lists are ready!")
    
    # --- ë‹¨ì¼ ë°ì´í„° --- 
    # (5-1) ë¦¬ë·° ê°œìˆ˜
    try:
        review_num = driver.find_element(By.CSS_SELECTOR, ".cont_evaluation > .total_evaluation > .color_b").text

        # --- ë”•ì…”ë„ˆë¦¬ ë°ì´í„° ---
        # (5-2) í‚¤ì›Œë“œ; 
        try:
            keys_list = driver.find_elements(By.CSS_SELECTOR, ".txt_likepoint")
            keys = []
            for key in keys_list:
                keys.append(key.text)   
            values_list = driver.find_elements(By.CSS_SELECTOR, ".num_likepoint")
            values = []
            for value in values_list:
                values.append(str(f"{int(value.text) / int(review_num) * 100:.1f}") + '%')
            keywords = dict(zip(keys, values))
        except:
            keywords = dict()
            

        # --- ë¦¬ìŠ¤íŠ¸ ë°ì´í„° ---
        # (5-3-1) ë¦¬ë·° ë‚ ì§œ (list)
        review_dates_list = driver.find_elements(By.CSS_SELECTOR, ".unit_info > .time_write")
        for i in review_dates_list:
            review_dates.append(i.text[:-1])

        # (5-3-2) ë¦¬ë·°ì–´ ì´ë¦„ (list)
        reviewer_names_list = driver.find_elements(By.CSS_SELECTOR, ".unit_info > .link_user")
        for i in reviewer_names_list:
            reviewer_names.append(i.text)

        # (5-3-3) ë¦¬ë·°ì–´ ë³„ì  (list)
        for i in driver.find_elements(By.CSS_SELECTOR,'.ico_star.inner_star')[2:-1]:
            i = int(''.join(re.findall(r'\d+', i.get_attribute('style')))) / 100 * 5
            review_ratings.append(f"{i:.1f}")

        # (5-3-4) ë¦¬ë·°ì–´ í‚¤ì›Œë“œ (list)
        for i in driver.find_elements(By.CSS_SELECTOR,'.list_evaluation')[:1]:
            i = i.get_attribute('innerHTML')
        pattern = r'<div class="star_info">.*?<div class="comment_info">'
        matches = re.findall(pattern, i, re.DOTALL)
        result_list = [match.strip() for match in matches]
        
        group_likepoint = driver.find_elements(By.CSS_SELECTOR,".group_likepoint")

        for i in result_list:
            if '<span class="ico_comm ico_like2">ì¶”ì²œí¬ì¸íŠ¸</span>' in i:
                review_keywords.append(group_likepoint.pop(0).text.strip().replace('\n', ', ').split(', '))
            else:
                review_keywords.append([])

        # (5-3-5) ë¦¬ë·° ë‚´ìš© (list)
        for i in driver.find_elements(By.CSS_SELECTOR,".comment_info > .txt_comment > span"):
            if i.text != '':
                review_contents.append(i.text)
            else:
                review_contents.append('')

        # (5-3-6) ë¦¬ë·°ì–´ í›„ê¸° ê°œìˆ˜ (list)
        reviewer_list = []
        for i, d in enumerate(driver.find_elements(By.CSS_SELECTOR,".unit_info > .txt_desc")):
            if (i+1) % 2 == 1:
                reviewer_review_nums.append(d.text)
        # (5-3-7) ë¦¬ë·°ì–´ í‰ê·  ë³„ì  (list)
            else:
                reviewer_review_avg_ratings.append(d.text)

    except:
        review_num = "0"
        keywords = dict()
        review_dates = []
        reviewer_names = []
        review_ratings = []
        review_keywords = []
        review_contents = []
        reviewer_review_nums = []
        reviewer_review_avg_ratings = []
    
    driver.quit()
    return review_num, keywords, review_dates, reviewer_names, review_ratings, review_keywords, review_contents, reviewer_review_nums, reviewer_review_avg_ratings


# In[4]:


######### ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ #########
# --- ë¼ì´ë¸ŒëŸ¬ë¦¬ - Selenium 1 ---
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

# --- ë¼ì´ë¸ŒëŸ¬ë¦¬ - Selenium 2 ---
from selenium.common.exceptions import NoSuchElementException
from selenium.common.exceptions import ElementNotInteractableException
from selenium.common.exceptions import StaleElementReferenceException
from selenium.common.exceptions import TimeoutException

# --- ë¼ì´ë¸ŒëŸ¬ë¦¬ - BeautifulSoup --- 
# from bs4 import BeautifulSoup

# --- ë¼ì´ë¸ŒëŸ¬ë¦¬ - ê¸°íƒ€ --- 
import requests
import json
import os
import time
from time import sleep
import re
from datetime import datetime

import pandas as pd
import openpyxl



######### í¬ë¡¬ ì„¸íŒ… #########
# --- Url ë¶ˆëŸ¬ì˜¤ê¸° --- 
url = 'https://map.kakao.com/'
service = Service()

# --- í¬ë¡¬ì°½ ì˜µì…˜ --- 
chrome_options = webdriver.ChromeOptions() 
chrome_options.add_argument('headless') # í¬ë¡¬ì°½ ìˆ¨ê¸°ê¸°
chrome_options.add_argument('lang=ko_KR')

# --- í¬ë¡¬ ë“œë¼ì´ë²„ ---
release = "https://chromedriver.storage.googleapis.com/LATEST_RELEASE"
version = requests.get(release).text
# driver = webdriver.Chrome(service=Service(ChromeDriverManager(version=version).install()))
driver = webdriver.Chrome(service=Service(ChromeDriverManager(version=version).install()), options=chrome_options)

driver.get(url)
driver.implicitly_wait(time_to_wait=5)
key_word = 'í™ëŒ€ ë§›ì§‘'  # ê²€ìƒ‰ì–´



######### ì½”ë“œ ì‹¤í–‰ (1) #########
# cssë¥¼ ì°¾ì„ ë•Œê¹Œì§€ 10ì´ˆ ëŒ€ê¸°
time_wait(10, 'div.box_searchbar > input.query')

# (1) ê²€ìƒ‰ì°½ ì°¾ê¸°
search = driver.find_element(By.CSS_SELECTOR, 'div.box_searchbar > input.query')
search.send_keys(key_word)  # ê²€ìƒ‰ì–´ ì…ë ¥
search.send_keys(Keys.ENTER)  # ì—”í„°ë²„íŠ¼ ëˆ„ë¥´ê¸°

sleep(1)

# (2-1) ì¥ì†Œíƒ­ í´ë¦­
place_tab = driver.find_element(By.CSS_SELECTOR, '#info\.main\.options > li.option1 > a')
place_tab.send_keys(Keys.ENTER)

sleep(1)

# (2-2) ì¸ê¸°ë„ìˆœ í•„í„° í´ë¦­
place_tab = driver.find_element(By.CSS_SELECTOR, '#info\.search\.place\.sort > li:nth-child(2) > a')
place_tab.send_keys(Keys.ENTER)

sleep(1)

# ë§›ì§‘ ë¦¬ìŠ¤íŠ¸
sinchon_list = driver.find_elements(By.CSS_SELECTOR, '.placelist > .PlaceItem')
print("List Crawling Success!")

# list ìƒì„±
final_list = []


# In[ ]:


# ì‹œì‘ ì‹œê°„
start = time.time()
print('[í¬ë¡¤ë§ ì‹œì‘...]')

# í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸ë§Œí¼ í¬ë¡¤ë§
page = 1    # í˜„ì¬ í¬ë¡¤ë§í•˜ëŠ” í˜ì´ì§€ê°€ ì „ì²´ì—ì„œ ëª‡ë²ˆì§¸ í˜ì´ì§€ì¸ì§€
page2 = 0   # 1 ~ 5ë²ˆì§¸ ì¤‘ ëª‡ë²ˆì§¸ì¸ì§€
error_cnt = 0

# í˜ì´ì§€ ë„˜ì–´ê°€ë©° ì¶œë ¥
while 1:
    try:
        page2 += 1
        print("**", page, "**")
        time.sleep(5)
        
        # (7) í˜ì´ì§€ ë²ˆí˜¸ í´ë¦­
        driver.find_element(By.XPATH, f'//*[@id="info.search.page.no{page2}"]').send_keys(Keys.ENTER)

        # *** í•¨ìˆ˜2 í˜¸ì¶œ ***
        final_list = sinchon_list_per_page() #ë§›ì§‘ ë¦¬ìŠ¤íŠ¸ ì „ì²´ ì •ë³´ í¬ë¡¤ë§ >> ê°€ì ¸ì˜¤ê¸°

        # í•´ë‹¹ í˜ì´ì§€ ë§›ì§‘ ë¦¬ìŠ¤íŠ¸
        sinchon_list = driver.find_elements(By.CSS_SELECTOR, '.placelist > .PlaceItem')
        
        if len(sinchon_list) < 15: # í•œ í˜ì´ì§€ì— ì¥ì†Œ ê°œìˆ˜ê°€ 15ê°œ ë¯¸ë§Œ? >> í•´ë‹¹ í˜ì´ì§€ëŠ” ë§ˆì§€ë§‰ í˜ì´ì§€
            break
        if not driver.find_element(By.XPATH, '//*[@id="info.search.page.next"]').is_enabled(): # ë‹¤ìŒ ë²„íŠ¼ X? >> ë§‰ í˜ì´ì§€
            break

        # (8) ë‹¤ì„¯ë²ˆì§¸ í˜ì´ì§€ê¹Œì§€ ì™”ë‹¤ë©´ ë‹¤ìŒ ë²„íŠ¼ì„ ëˆ„ë¥´ê³  page2 = 0ìœ¼ë¡œ ì´ˆê¸°í™”
        if page2 % 5 == 0:
            time.sleep(5)
            driver.find_element(By.XPATH, '//*[@id="info.search.page.next"]').send_keys(Keys.ENTER)
            page2 = 0
        page += 1

    except Exception as e:
        error_cnt += 1
        print(e)
        print('ERROR!' * 3)

        if error_cnt > 5:
            break

print('[ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ]\nì†Œìš” ì‹œê°„ :', time.time() - start)
print(final_list)
driver.quit()  # ì‘ì—…ì´ ëë‚˜ë©´ ì°½ì„ ë‹«ëŠ”ë‹¤.


# In[ ]:


import pandas as pd
import openpyxl
# xlsx íŒŒì¼ë¡œ ì €ì¥
df = pd.DataFrame(final_list)
df.to_excel('final_data.xlsx', index = False, encoding = 'utf-8-sig')
df

# json íŒŒì¼ë¡œ ì €ì¥
with open('final_data.json', 'w', encoding='utf-8') as f:
    json.dump(final_list, f, indent=4, ensure_ascii=False)
print(final_list)


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# ### 07.31 error case ###
# [ğŸ‘€] Data Exceeded ì´ìŠˆ
# - ![image-9.png](attachment:image-9.png)
# - í•´ê²°: https://dev-cini.tistory.com/38
# 
# [âœ…] ë¦¬ë·° ì´ ê°œìˆ˜ë‘ list lenghtë‘ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ì´ìŠˆ
#     - driver.find_elementsë¡œ í´ë¦­í•˜ê¸° ì „ì— time.sleep() ê¼­ í•´ì¤˜ì•¼ í•¨
# [âœ…] ë¦¬ë·° ë§í¬ ì•ˆì—ì„œ, review_numê¹Œì§€ëŠ” ì˜ ì°íˆëŠ”ë°, list ë°ì´í„° 3ê¹Œì§€ë§Œ ì°íˆëŠ” ì´ìŠˆ
# 1. (X) í´ë¦­ì´ ì•ˆ ë˜ì—ˆê±°ë‚˜ 
#     - (í™•ì¸) í´ë¦­ ìˆ˜ ì°ì–´ë³´ê¸° by í•¨ìˆ˜ 3 no.38(print('click!') >> ì¶”ê°€
#     - í•¨ìˆ˜ 3 no.23(webdriverwait(3,code))ì˜ ì‹œê°„ì„ ë” ëŠ˜ë¦¬ê¸°???
# 2. (X) css selectê°€ ì œëŒ€ë¡œ ì•ˆ ë˜ì—ˆê±°ë‚˜
#     - í•¨ìˆ˜ 3 no.78(time.sleep(n)) ì¶”ê°€í•˜ê¸°???
# 3. (O) ë‹¤ë¥¸ css selectorë¥¼ ì„ íƒ
#     - 'ë©”ë‰´ ë”ë³´ê¸°'ê°€ ìˆëŠ” ê²½ìš°, ì´ css selectorë¥¼ ë¨¼ì € ì„ íƒí•˜ê²Œ ë¨
# ![image.png](attachment:image.png)
# 
# [âœ…] 2nd case - í¬ë¡¤ë§ í•˜ë‹¤ê°€ disconnnected ë˜ëŠ” ì´ìŠˆ
# - ì²« ì—ëŸ¬: ```Message: stale element reference: stale element not found```
# ![image-5.png](attachment:image-5.png)
# - ê·¸ ì´í›„ì— ë§›ì§‘ ì •ë³´ë‘ ë¦¬ë·° ì •ë³´ ë¶ˆì¼ì¹˜í•¨ (ì „ìê°€ ì˜ëª»ë¨
# ![image-6.png](attachment:image-6.png)
# - ë‘˜ì§¸ ì—ëŸ¬: 1ì™€ ë™ì¼
# ![image-7.png](attachment:image-7.png)
# - ë§ˆì§€ë§‰ ì—ëŸ¬: í˜ì´ì§€ë„ ëª» ì°¾ê³  ë
# ![image-8.png](attachment:image-8.png)
# 
# [âœ…] 1st case - í¬ë¡¤ë§ í•˜ë‹¤ê°€ disconnnected ë˜ëŠ” ì´ìŠˆ: ** 10 **ì˜ 12. ìš©ìš©ì„ ìƒ ë¶€í„° ë§‰í˜
#     1. (X) time.sleep(2) ë” ì£¼ê¸°
#     2. (O) í•¨ìˆ˜ 3 no.23(webdriverwait(3,code)) ë” ì£¼ê¸°
# ![image-2.png](attachment:image-2.png)
# - CSS SELECT ê¹Œì§€ëŠ” OK.
# ![image-4.png](attachment:image-4.png)
# - ```Message: disconnected: not connected to DevTools
#   (failed to check if window was closed: disconnected: not connected to DevTools)
#   (Session info: headless chrome=115.0.5790.114)
# Stacktrace:```
# ![image-3.png](attachment:image-3.png)

# In[ ]:




